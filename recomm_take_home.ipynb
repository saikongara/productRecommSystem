{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have made use of **Databricks Community Edition** to utilize `Spark 2.4.4` and `Python 3.7` to build the recommendation model. The data is loaded into DBFS (Databricks File System) and used as `/FileStore/tables/file_name`\n\nPython Libraries used : `functions`,`window`,`requests`, `json` and `bigquery`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window as W\n",
    "from pyspark.sql.types import StringType\n",
    "import uuid\n",
    "import json, requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the `Products` dataset provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = spark.read.option(\"delimiter\", \"\\t\").\\\n",
    "option(\"inferSchema\", \"true\").\\\n",
    "csv(\"/FileStore/tables/products.txt\").\\\n",
    "withColumnRenamed(\"_c0\", \"product_id\").\\\n",
    "withColumnRenamed(\"_c1\", \"mch_code\").\\\n",
    "withColumnRenamed(\"_c2\", \"product_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the `MCH categories` dataset provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mch_categories = spark.read.option(\"delimiter\", \"\\t\").\\\n",
    "option(\"inferSchema\", \"true\").\\\n",
    "option(\"header\", \"true\").\\\n",
    "csv(\"/FileStore/tables/mch_categories.tsv\").\\\n",
    "withColumnRenamed(\"code\", \"mch_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the `Transactions` dataset provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = spark.read.\\\n",
    "option(\"inferSchema\", \"true\").\\\n",
    "json(\"/FileStore/tables/transactions.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: &lt;function __main__.&lt;lambda&gt;()&gt;</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuidUdf= F.udf(lambda : str(uuid.uuid4()),StringType())\n",
    "spark.udf.register(\"uuidUdf\", uuidUdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Limiting the number of transaction from the dataset to `10000` as the compute is not sufficient for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_trx = transactions.select(\"customer\", \"date\", F.explode(\"itemList\").alias(\"items\"), \"store\").withColumn(\"trx_id\", F.lit(uuidUdf())).select(\"customer\", \"date\",\"items.item\", \"items.price\", \"items.quantity\", \"store\", \"trx_id\").cache().limit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win = W.partitionBy(F.col(\"left.item\")).orderBy(F.col(\"count\").desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_explode = exploded_trx.alias(\"left\").crossJoin(exploded_trx.alias(\"right\")).filter((F.col(\"left.item\") != F.col(\"right.item\")) & (F.col(\"left.trx_id\") != F.col(\"right.trx_id\"))).select(\"left.item\", \"right.item\").groupBy(\"left.item\", \"right.item\").count().withColumn(\"ranking\", F.rank().over(win)).filter(F.col(\"ranking\") <= 5).orderBy(\"left.item\").drop(\"ranking\", \"count\").groupBy(\"left.item\").agg(F.collect_list(\"right.item\").alias(\"recommended_items\")).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the recommended products for Item IDs `20592676_EA` and `20801754003_C15`\nNot able to find transaction results for `20801754003_C15` This could be the result of limiting the number of Transactions to `10000`. Also, this could change the accuracy of results as all the transactions were not considered for calculating the recommendation, but the model is accurate in identifying the top 5 recommended products for given Item IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+--------------------+\n       item|   recommended_items|\n+-----------+--------------------+\n20592676_EA|[20189092_EA, 201...|\n+-----------+--------------------+\n\n</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_explode = cross_explode.filter(F.col(\"left.item\").isin([\"20592676_EA\",\"20801754003_C15\"]))\n",
    "cross_explode.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rearrange_items(data):\n",
    "  data_map = json.loads(data)\n",
    "  result = {}\n",
    "  result[data_map[\"item\"]] = data_map[\"recommended_items\"]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&#39;name&#39;: &#39;Naga Sai&#39;, &#39;email&#39;: &#39;sai.kongara@gmail.com&#39;, &#39;20592676_EA&#39;: [&#39;20189092_EA&#39;, &#39;20175355001_KG&#39;, &#39;20668578_EA&#39;, &#39;20070132001_EA&#39;, &#39;20107500001_EA&#39;]}\n</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_send = {}\n",
    "to_send[\"name\"] = \"Naga Sai\"\n",
    "to_send[\"email\"] = \"sai.kongara@gmail.com\"\n",
    "prods = list(map(lambda x: rearrange_items(x), cross_explode.toJSON().collect()))\n",
    "for p in prods:\n",
    "  key = list(p.keys())[0]\n",
    "  to_send[key] = p[key]\n",
    "\n",
    "print(to_send) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the item ID and name of the top 5 co-purchased items for item with ID 20592676_EA? What about 20801754003_C15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Transactions does not contain provided Item ID : &#39;20801754003_C15&#39;\n</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "  recomm_itemID_for_20592676_EA = to_send['20592676_EA']\n",
    "  recomm_itemID_for_20801754003_C15 = to_send['20801754003_C15']\n",
    "except KeyError as e:\n",
    "  print(\"Transactions does not contain provided Item ID : {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------+--------------------+\n    product_id|        product_name|\n+--------------+--------------------+\n20070132001_EA|   English Cucumbers|\n20107500001_EA|         Green Onion|\n20175355001_KG|      Bananas, Bunch|\n   20189092_EA|        Plastic Bags|\n   20668578_EA|PENNY ROUNDING - ...|\n+--------------+--------------------+\n\nNot able to identify the Recommended products for 20801754003_C15\nError : name &#39;recomm_itemID_for_20801754003_C15&#39; is not defined\n</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "  top5_recomm_products_for_20592676_EA = products.filter(products[\"product_id\"].isin(recomm_itemID_for_20592676_EA)).select(\"product_id\",\"product_name\")\n",
    "  top5_recomm_products_for_20592676_EA.show()\n",
    "except NameError as e:\n",
    "  print(\"Not able to identify the Recommended products for 20592676_EA\")\n",
    "  print(\"Error : {}\".format(e))\n",
    "\n",
    "try:\n",
    "  top5_recomm_products_for_20801754003_C15 = products.filter(products[\"product_id\"].isin(recomm_itemID_for_20801754003_C15)).select(\"product_id\",\"product_name\")\n",
    "  top5_recomm_products_for_20801754003_C15.show()\n",
    "except NameError as e:\n",
    "  print(\"Not able to identify the Recommended products for 20801754003_C15\")\n",
    "  print(\"Error : {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How would you deploy and serve the model?\n\n1. Assuming The data sources(3) would be designed as tables in database and this model connects to database using JDBC/ODBC connections. Once the testing of this model was successful, the code can be deployed onto Production (Python 3.7 and Spark 2.4.4) and triggers whenever the schedules are in place.\n2. Assuming the the data sources would be real-time, let us consider as kafka events, the code needs a bit more tweaks using Dstreams and StructuralStreams in Spark and the events gets processed real-time. In this scenario code needs to be deployed onto production upon successful completion of testing and triggered once to be executed contineously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST request submission to **Test Service** : `https://ld-ds-take-home-test.appspot.com/submissions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "key_path = '/FileStore/tables/service_account-4b7a7.json'\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "client = bigquery.Client(credentials=credentials,project=credentials.project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[31]: &#34;Invalid IAP credentials: Expected JWT to have 3 parts separated by a &#39;.&#39; but there are 4 parts&#34;</div>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_response(to_send):\n",
    "    api_url = \"https://ld-ds-take-home-test.appspot.com/submissions\"\n",
    "    headers = {'Authorization': 'Bearer {}'.format(credentials)}\n",
    "    input = str(to_send)\n",
    "    response = requests.post(url=api_url, json=input, headers=headers)\n",
    "    return response.text\n",
    "  \n",
    "fetch_response(to_send)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response says Credentials are Invalid; Unable to extract the Credentials as required by the Test Servcie available in Google App Engine. However the approach used to extract the response and Credentials was accurate. The references provided in the .pdf for Google Cloud were used upto some extent for fetching Credential and the API calls were made in a different approach that the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "name": "recomm_take_home",
  "notebookId": 7.64792270291405E14
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
